{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ee6e482-42a4-4cd1-8bbb-f81dc08a2015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import pandas as pd     # pandas:2.1.0\n",
    "import numpy as np      # numpy:1.26\n",
    "import matplotlib.pyplot as plt   # matplotlib: 3.8.0\n",
    "import seaborn as sns    # seaborn: 0.12.2\n",
    "import scipy.stats as stats # scipy:1.11.2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9653f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 2.1.0\n",
      "numpy: 1.25.2\n",
      "matplotlib: 3.8.0\n",
      "scipy: 1.11.2\n",
      "seaborn: 0.12.2\n"
     ]
    }
   ],
   "source": [
    "# This code will tell the version the libraries installed in the current environment\n",
    "\n",
    "import pkg_resources\n",
    "\n",
    "# List all installed packages and their versions\n",
    "installed_packages = {pkg.key: pkg.version for pkg in pkg_resources.working_set}\n",
    "\n",
    "# List of imported libraries\n",
    "imported_libraries = ['pandas', 'numpy', 'matplotlib', 'scipy', 'seaborn']\n",
    "\n",
    "# Print imported libraries and their versions\n",
    "for library in imported_libraries:\n",
    "    if library in installed_packages:\n",
    "        print(f\"{library}: {installed_packages[library]}\")\n",
    "    else:\n",
    "        print(f\"{library}: Not found in installed packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4197f0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User will give only the path of the folder & code will look for all the csv file & then create all the DataFrame automatically as per the name of the file\n",
    "\n",
    "mypath = \"/Users/pratyushmahato/Desktop/AnalytixLabs/python_foundation/Basic Statistics - Hypothesis Testing\" # folder path of file location\n",
    "csv_files = []\n",
    "def search_csv_file():\n",
    "    \"\"\"\n",
    "    function to search all csv files in a folder path\n",
    "    \"\"\"\n",
    "    for files in os.listdir(mypath):\n",
    "        if files.endswith('.csv'):\n",
    "            csv_files.append(files)\n",
    "\n",
    "search_csv_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe290a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = []\n",
    "dataframe_names = []\n",
    "\n",
    "def DataframeNameCreation_FilePathCreation():\n",
    "    \"\"\"\n",
    "    function to create DataFrame names & File Path\n",
    "    \"\"\"\n",
    "    for i in csv_files:\n",
    "        x = 'df_' + str(i).split('/')[-1].split('.')[0]\n",
    "        y = os.path.join(mypath ,i)\n",
    "        dataframe_names.append(x)\n",
    "        file_paths.append(y)\n",
    "\n",
    "DataframeNameCreation_FilePathCreation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204c3664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALl Dataframes are:\n",
      "df_Price_Quotes\n",
      "df_Films\n",
      "df_Priority_Assessment\n",
      "df_Treatment_Facility\n",
      "df_LoansData\n"
     ]
    }
   ],
   "source": [
    "def read_dataframes(dataframe_names, file_paths):\n",
    "    \"\"\"\n",
    "    Read data from CSV files into dataframes and assign dataframe names automatically.\n",
    "\n",
    "    Args:\n",
    "        dataframe_names (list of str): List of desired dataframe names.\n",
    "        file_paths (list of str): List of file paths for the CSV files.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary of dataframes with automatic naming.\n",
    "    \"\"\"\n",
    "    dataframes = {}\n",
    "    \n",
    "    for file_path, df_name in zip(file_paths, dataframe_names):\n",
    "        try:\n",
    "            # Read data from the file into a dataframe\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Store the dataframe in the dictionary using the specified df_name\n",
    "            dataframes[df_name] = df\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading data from {file_path}: {str(e)}\")\n",
    "    \n",
    "    return dataframes\n",
    "\n",
    "\n",
    "# Call the function to read data and assign dataframe names\n",
    "dataframes = read_dataframes(dataframe_names, file_paths)\n",
    "\n",
    "# Automate the creation of variables for dataframes using a loop\n",
    "for df_name in dataframe_names:\n",
    "    globals()[df_name] = dataframes[df_name]\n",
    "\n",
    "# Print all dataframe names\n",
    "print(\"ALl Dataframes are:\")\n",
    "for df_name in dataframes.keys():\n",
    "    print(df_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531615fb",
   "metadata": {},
   "source": [
    "# Business Problem 1: Loans Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3bdb2e",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a29b4713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount.Requested</th>\n",
       "      <th>Amount.Funded.By.Investors</th>\n",
       "      <th>Interest.Rate</th>\n",
       "      <th>Loan.Length</th>\n",
       "      <th>Loan.Purpose</th>\n",
       "      <th>Debt.To.Income.Ratio</th>\n",
       "      <th>State</th>\n",
       "      <th>Home.Ownership</th>\n",
       "      <th>Monthly.Income</th>\n",
       "      <th>FICO.Range</th>\n",
       "      <th>Open.CREDIT.Lines</th>\n",
       "      <th>Revolving.CREDIT.Balance</th>\n",
       "      <th>Inquiries.in.the.Last.6.Months</th>\n",
       "      <th>Employment.Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>8.90%</td>\n",
       "      <td>36 months</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>14.90%</td>\n",
       "      <td>SC</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>6541.67</td>\n",
       "      <td>735-739</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14272.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19200.0</td>\n",
       "      <td>19200.0</td>\n",
       "      <td>12.12%</td>\n",
       "      <td>36 months</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>28.36%</td>\n",
       "      <td>TX</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>4583.33</td>\n",
       "      <td>715-719</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>21.98%</td>\n",
       "      <td>60 months</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>23.81%</td>\n",
       "      <td>CA</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>690-694</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21977.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>9975.0</td>\n",
       "      <td>9.99%</td>\n",
       "      <td>36 months</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>14.30%</td>\n",
       "      <td>KS</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>3833.33</td>\n",
       "      <td>695-699</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9346.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12000.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>11.71%</td>\n",
       "      <td>36 months</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>18.78%</td>\n",
       "      <td>NJ</td>\n",
       "      <td>RENT</td>\n",
       "      <td>3195.00</td>\n",
       "      <td>695-699</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14469.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9 years</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Amount.Requested  Amount.Funded.By.Investors Interest.Rate Loan.Length  \\\n",
       "0           20000.0                     20000.0         8.90%   36 months   \n",
       "1           19200.0                     19200.0        12.12%   36 months   \n",
       "2           35000.0                     35000.0        21.98%   60 months   \n",
       "3           10000.0                      9975.0         9.99%   36 months   \n",
       "4           12000.0                     12000.0        11.71%   36 months   \n",
       "\n",
       "         Loan.Purpose Debt.To.Income.Ratio State Home.Ownership  \\\n",
       "0  debt_consolidation               14.90%    SC       MORTGAGE   \n",
       "1  debt_consolidation               28.36%    TX       MORTGAGE   \n",
       "2  debt_consolidation               23.81%    CA       MORTGAGE   \n",
       "3  debt_consolidation               14.30%    KS       MORTGAGE   \n",
       "4         credit_card               18.78%    NJ           RENT   \n",
       "\n",
       "   Monthly.Income FICO.Range  Open.CREDIT.Lines  Revolving.CREDIT.Balance  \\\n",
       "0         6541.67    735-739               14.0                   14272.0   \n",
       "1         4583.33    715-719               12.0                   11140.0   \n",
       "2        11500.00    690-694               14.0                   21977.0   \n",
       "3         3833.33    695-699               10.0                    9346.0   \n",
       "4         3195.00    695-699               11.0                   14469.0   \n",
       "\n",
       "   Inquiries.in.the.Last.6.Months Employment.Length  \n",
       "0                             2.0          < 1 year  \n",
       "1                             1.0           2 years  \n",
       "2                             1.0           2 years  \n",
       "3                             0.0           5 years  \n",
       "4                             0.0           9 years  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LoansData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ca4036b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2500 entries, 0 to 2499\n",
      "Data columns (total 14 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Amount.Requested                2499 non-null   float64\n",
      " 1   Amount.Funded.By.Investors      2499 non-null   float64\n",
      " 2   Interest.Rate                   2498 non-null   object \n",
      " 3   Loan.Length                     2500 non-null   object \n",
      " 4   Loan.Purpose                    2500 non-null   object \n",
      " 5   Debt.To.Income.Ratio            2499 non-null   object \n",
      " 6   State                           2500 non-null   object \n",
      " 7   Home.Ownership                  2499 non-null   object \n",
      " 8   Monthly.Income                  2499 non-null   float64\n",
      " 9   FICO.Range                      2498 non-null   object \n",
      " 10  Open.CREDIT.Lines               2497 non-null   float64\n",
      " 11  Revolving.CREDIT.Balance        2497 non-null   float64\n",
      " 12  Inquiries.in.the.Last.6.Months  2497 non-null   float64\n",
      " 13  Employment.Length               2423 non-null   object \n",
      "dtypes: float64(6), object(8)\n",
      "memory usage: 273.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_LoansData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f591c5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Amount.Requested                  0.04\n",
       "Amount.Funded.By.Investors        0.04\n",
       "Interest.Rate                     0.08\n",
       "Loan.Length                       0.00\n",
       "Loan.Purpose                      0.00\n",
       "Debt.To.Income.Ratio              0.04\n",
       "State                             0.00\n",
       "Home.Ownership                    0.04\n",
       "Monthly.Income                    0.04\n",
       "FICO.Range                        0.08\n",
       "Open.CREDIT.Lines                 0.12\n",
       "Revolving.CREDIT.Balance          0.12\n",
       "Inquiries.in.the.Last.6.Months    0.12\n",
       "Employment.Length                 3.08\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of NULL rows in each column\n",
    "(df_LoansData.isnull().sum() / df_LoansData.shape[0] ) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa012687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Amount.Requested in LoansData\n",
    "\n",
    "df_LoansData[df_LoansData['Amount.Requested'].isnull()]\n",
    "# the row number in which Amount.Requested is NULL is 2487. It also has another NULL column with column name Interest.Rate. So dropping this row because it has 2 NULL value & it constitutes only 0.04% of the whole data\n",
    "df_LoansData = df_LoansData.dropna(subset=['Amount.Requested'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd5332f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Amount.Funded.By.Investors in LoansData\n",
    "\n",
    "df_LoansData[df_LoansData['Amount.Funded.By.Investors'].isnull()]\n",
    "# the row number in which Amount.Requested is NULL is 2490. So dropping this row because it constitutes only 0.04% of the whole data\n",
    "df_LoansData = df_LoansData.dropna(subset=['Amount.Funded.By.Investors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "155ad974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Interest.Rate in LoansData\n",
    "\n",
    "df_LoansData[df_LoansData['Interest.Rate'].isnull()]\n",
    "# the row number in which Amount.Requested is NULL is 2484. So dropping this row because it constitutes only 0.04% of the whole data\n",
    "df_LoansData = df_LoansData.dropna(subset=['Interest.Rate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1f424f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2496 entries, 0 to 2499\n",
      "Data columns (total 14 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Amount.Requested                2496 non-null   float64\n",
      " 1   Amount.Funded.By.Investors      2496 non-null   float64\n",
      " 2   Interest.Rate                   2496 non-null   object \n",
      " 3   Loan.Length                     2496 non-null   object \n",
      " 4   Loan.Purpose                    2496 non-null   object \n",
      " 5   Debt.To.Income.Ratio            2496 non-null   object \n",
      " 6   State                           2496 non-null   object \n",
      " 7   Home.Ownership                  2496 non-null   object \n",
      " 8   Monthly.Income                  2495 non-null   float64\n",
      " 9   FICO.Range                      2494 non-null   object \n",
      " 10  Open.CREDIT.Lines               2493 non-null   float64\n",
      " 11  Revolving.CREDIT.Balance        2493 non-null   float64\n",
      " 12  Inquiries.in.the.Last.6.Months  2493 non-null   float64\n",
      " 13  Employment.Length               2419 non-null   object \n",
      "dtypes: float64(6), object(8)\n",
      "memory usage: 292.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Column Debt.To.Income.Ratio in LoansData\n",
    "\n",
    "df_LoansData[df_LoansData['Debt.To.Income.Ratio'].isnull()]\n",
    "# the row number in which Amount.Requested is NULL is 2492. It also has another NULL column with column name Home.Ownership.Rate So dropping this row because it constitutes only 0.04% of the whole data\n",
    "df_LoansData = df_LoansData.dropna(subset=['Debt.To.Income.Ratio'])\n",
    "df_LoansData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da01bc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2495 entries, 0 to 2499\n",
      "Data columns (total 14 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Amount.Requested                2495 non-null   float64\n",
      " 1   Amount.Funded.By.Investors      2495 non-null   float64\n",
      " 2   Interest.Rate                   2495 non-null   object \n",
      " 3   Loan.Length                     2495 non-null   object \n",
      " 4   Loan.Purpose                    2495 non-null   object \n",
      " 5   Debt.To.Income.Ratio            2495 non-null   object \n",
      " 6   State                           2495 non-null   object \n",
      " 7   Home.Ownership                  2495 non-null   object \n",
      " 8   Monthly.Income                  2495 non-null   float64\n",
      " 9   FICO.Range                      2493 non-null   object \n",
      " 10  Open.CREDIT.Lines               2493 non-null   float64\n",
      " 11  Revolving.CREDIT.Balance        2493 non-null   float64\n",
      " 12  Inquiries.in.the.Last.6.Months  2493 non-null   float64\n",
      " 13  Employment.Length               2418 non-null   object \n",
      "dtypes: float64(6), object(8)\n",
      "memory usage: 292.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Column Monthly.Income in LoansData\n",
    "\n",
    "df_LoansData[df_LoansData['Monthly.Income'].isnull()]\n",
    "# the row number in which Amount.Requested is NULL is 366. It has 3 other NULL columns also namely, Open.CREDIT.Lines, Revolving.CREDIT.Balance, Inquiries.in.the.Last.6.Months. So dropping this row because it has 4 NULL values & it constitutes only 0.04% of the whole data\n",
    "df_LoansData = df_LoansData.dropna(subset=['Monthly.Income'])\n",
    "df_LoansData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46d73609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2493 entries, 0 to 2499\n",
      "Data columns (total 14 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Amount.Requested                2493 non-null   float64\n",
      " 1   Amount.Funded.By.Investors      2493 non-null   float64\n",
      " 2   Interest.Rate                   2493 non-null   object \n",
      " 3   Loan.Length                     2493 non-null   object \n",
      " 4   Loan.Purpose                    2493 non-null   object \n",
      " 5   Debt.To.Income.Ratio            2493 non-null   object \n",
      " 6   State                           2493 non-null   object \n",
      " 7   Home.Ownership                  2493 non-null   object \n",
      " 8   Monthly.Income                  2493 non-null   float64\n",
      " 9   FICO.Range                      2493 non-null   object \n",
      " 10  Open.CREDIT.Lines               2491 non-null   float64\n",
      " 11  Revolving.CREDIT.Balance        2491 non-null   float64\n",
      " 12  Inquiries.in.the.Last.6.Months  2491 non-null   float64\n",
      " 13  Employment.Length               2416 non-null   object \n",
      "dtypes: float64(6), object(8)\n",
      "memory usage: 292.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Column FICO.Range in LoansData\n",
    "\n",
    "df_LoansData[df_LoansData['FICO.Range'].isnull()]\n",
    "# the row number in which Amount.Requested is NULL are 2488 & 2494. So dropping this row because it constitutes only 0.08% of the whole data\n",
    "df_LoansData = df_LoansData.dropna(subset=['FICO.Range'])\n",
    "df_LoansData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a72fe86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2491 entries, 0 to 2499\n",
      "Data columns (total 14 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Amount.Requested                2491 non-null   float64\n",
      " 1   Amount.Funded.By.Investors      2491 non-null   float64\n",
      " 2   Interest.Rate                   2491 non-null   object \n",
      " 3   Loan.Length                     2491 non-null   object \n",
      " 4   Loan.Purpose                    2491 non-null   object \n",
      " 5   Debt.To.Income.Ratio            2491 non-null   object \n",
      " 6   State                           2491 non-null   object \n",
      " 7   Home.Ownership                  2491 non-null   object \n",
      " 8   Monthly.Income                  2491 non-null   float64\n",
      " 9   FICO.Range                      2491 non-null   object \n",
      " 10  Open.CREDIT.Lines               2491 non-null   float64\n",
      " 11  Revolving.CREDIT.Balance        2490 non-null   float64\n",
      " 12  Inquiries.in.the.Last.6.Months  2490 non-null   float64\n",
      " 13  Employment.Length               2414 non-null   object \n",
      "dtypes: float64(6), object(8)\n",
      "memory usage: 291.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Column Open.CREDIT.Lines in LoansData\n",
    "\n",
    "df_LoansData[df_LoansData['Open.CREDIT.Lines'].isnull()]\n",
    "# the row number in which Amount.Requested is NULL are 1594 & 2489. So dropping this row because it constitutes only 0.08% of the whole data\n",
    "df_LoansData = df_LoansData.dropna(subset=['Open.CREDIT.Lines'])\n",
    "df_LoansData.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a99e0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2490 entries, 0 to 2499\n",
      "Data columns (total 14 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Amount.Requested                2490 non-null   float64\n",
      " 1   Amount.Funded.By.Investors      2490 non-null   float64\n",
      " 2   Interest.Rate                   2490 non-null   object \n",
      " 3   Loan.Length                     2490 non-null   object \n",
      " 4   Loan.Purpose                    2490 non-null   object \n",
      " 5   Debt.To.Income.Ratio            2490 non-null   object \n",
      " 6   State                           2490 non-null   object \n",
      " 7   Home.Ownership                  2490 non-null   object \n",
      " 8   Monthly.Income                  2490 non-null   float64\n",
      " 9   FICO.Range                      2490 non-null   object \n",
      " 10  Open.CREDIT.Lines               2490 non-null   float64\n",
      " 11  Revolving.CREDIT.Balance        2490 non-null   float64\n",
      " 12  Inquiries.in.the.Last.6.Months  2489 non-null   float64\n",
      " 13  Employment.Length               2413 non-null   object \n",
      "dtypes: float64(6), object(8)\n",
      "memory usage: 291.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Column Revolving.CREDIT.Balance in LoansData\n",
    "\n",
    "df_LoansData[df_LoansData['Revolving.CREDIT.Balance'].isnull()]\n",
    "# the row number in which Amount.Requested is NULL is 2482. So dropping this row because it constitutes only 0.04% of the whole data\n",
    "df_LoansData = df_LoansData.dropna(subset=['Revolving.CREDIT.Balance'])\n",
    "df_LoansData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "166b179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametric test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a66cafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       735-739\n",
       "1       715-719\n",
       "2       690-694\n",
       "3       695-699\n",
       "4       695-699\n",
       "         ...   \n",
       "2495    705-709\n",
       "2496    740-744\n",
       "2497    680-684\n",
       "2498    675-679\n",
       "2499    670-674\n",
       "Name: FICO.Range, Length: 2490, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LoansData['FICO.Range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe6e4b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Home.Ownership\n",
       "MORTGAGE    1144\n",
       "RENT        1141\n",
       "OWN          200\n",
       "OTHER          5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LoansData['Home.Ownership'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e33365ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2489 entries, 0 to 2499\n",
      "Data columns (total 14 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Amount.Requested                2489 non-null   float64\n",
      " 1   Amount.Funded.By.Investors      2489 non-null   float64\n",
      " 2   Interest.Rate                   2489 non-null   object \n",
      " 3   Loan.Length                     2489 non-null   object \n",
      " 4   Loan.Purpose                    2489 non-null   object \n",
      " 5   Debt.To.Income.Ratio            2489 non-null   object \n",
      " 6   State                           2489 non-null   object \n",
      " 7   Home.Ownership                  2489 non-null   object \n",
      " 8   Monthly.Income                  2489 non-null   float64\n",
      " 9   FICO.Range                      2489 non-null   object \n",
      " 10  Open.CREDIT.Lines               2489 non-null   float64\n",
      " 11  Revolving.CREDIT.Balance        2489 non-null   float64\n",
      " 12  Inquiries.in.the.Last.6.Months  2489 non-null   float64\n",
      " 13  Employment.Length               2413 non-null   object \n",
      "dtypes: float64(6), object(8)\n",
      "memory usage: 291.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Column Inquiries.in.the.Last.6.Months in LoansData\n",
    "\n",
    "df_LoansData[df_LoansData['Inquiries.in.the.Last.6.Months'].isnull()]\n",
    "# the row number in which Amount.Requested is NULL is 2491. So dropping this row because it constitutes only 0.04% of the whole data\n",
    "df_LoansData = df_LoansData.dropna(subset=['Inquiries.in.the.Last.6.Months'])\n",
    "df_LoansData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a0536ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Employment.Length in LoansData\n",
    "\n",
    "df_LoansData[df_LoansData['Employment.Length'].isnull()]\n",
    "# there are 76 NULL values. This is a categorical column. so imputing the NULL values with mode of the column\n",
    "df_LoansData['Employment.Length'] = df_LoansData['Employment.Length'].astype(str)\n",
    "Employment_Length_mode= str(df_LoansData['Employment.Length'].mode())\n",
    "df_LoansData['Employment.Length'].fillna(value=Employment_Length_mode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e12b1e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2489 entries, 0 to 2499\n",
      "Data columns (total 14 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Amount.Requested                2489 non-null   float64\n",
      " 1   Amount.Funded.By.Investors      2489 non-null   float64\n",
      " 2   Interest.Rate                   2489 non-null   object \n",
      " 3   Loan.Length                     2489 non-null   object \n",
      " 4   Loan.Purpose                    2489 non-null   object \n",
      " 5   Debt.To.Income.Ratio            2489 non-null   object \n",
      " 6   State                           2489 non-null   object \n",
      " 7   Home.Ownership                  2489 non-null   object \n",
      " 8   Monthly.Income                  2489 non-null   float64\n",
      " 9   FICO.Range                      2489 non-null   object \n",
      " 10  Open.CREDIT.Lines               2489 non-null   float64\n",
      " 11  Revolving.CREDIT.Balance        2489 non-null   float64\n",
      " 12  Inquiries.in.the.Last.6.Months  2489 non-null   float64\n",
      " 13  Employment.Length               2489 non-null   object \n",
      "dtypes: float64(6), object(8)\n",
      "memory usage: 291.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_LoansData.info()\n",
    "# In the original dataset we had 2500 rows. Now we have 2489 rows, i.e. we have more than 99% of the original data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20510304-eddf-43fc-b072-ea044101c45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount.Requested</th>\n",
       "      <th>Amount.Funded.By.Investors</th>\n",
       "      <th>Interest.Rate</th>\n",
       "      <th>Loan.Length</th>\n",
       "      <th>Loan.Purpose</th>\n",
       "      <th>Debt.To.Income.Ratio</th>\n",
       "      <th>State</th>\n",
       "      <th>Home.Ownership</th>\n",
       "      <th>Monthly.Income</th>\n",
       "      <th>FICO.Range</th>\n",
       "      <th>Open.CREDIT.Lines</th>\n",
       "      <th>Revolving.CREDIT.Balance</th>\n",
       "      <th>Inquiries.in.the.Last.6.Months</th>\n",
       "      <th>Employment.Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>8.90%</td>\n",
       "      <td>36 months</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>14.90%</td>\n",
       "      <td>SC</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>6541.67</td>\n",
       "      <td>735-739</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14272.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19200.0</td>\n",
       "      <td>19200.0</td>\n",
       "      <td>12.12%</td>\n",
       "      <td>36 months</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>28.36%</td>\n",
       "      <td>TX</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>4583.33</td>\n",
       "      <td>715-719</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>21.98%</td>\n",
       "      <td>60 months</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>23.81%</td>\n",
       "      <td>CA</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>690-694</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21977.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>9975.0</td>\n",
       "      <td>9.99%</td>\n",
       "      <td>36 months</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>14.30%</td>\n",
       "      <td>KS</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>3833.33</td>\n",
       "      <td>695-699</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9346.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12000.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>11.71%</td>\n",
       "      <td>36 months</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>18.78%</td>\n",
       "      <td>NJ</td>\n",
       "      <td>RENT</td>\n",
       "      <td>3195.00</td>\n",
       "      <td>695-699</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14469.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9 years</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Amount.Requested  Amount.Funded.By.Investors Interest.Rate Loan.Length  \\\n",
       "0           20000.0                     20000.0         8.90%   36 months   \n",
       "1           19200.0                     19200.0        12.12%   36 months   \n",
       "2           35000.0                     35000.0        21.98%   60 months   \n",
       "3           10000.0                      9975.0         9.99%   36 months   \n",
       "4           12000.0                     12000.0        11.71%   36 months   \n",
       "\n",
       "         Loan.Purpose Debt.To.Income.Ratio State Home.Ownership  \\\n",
       "0  debt_consolidation               14.90%    SC       MORTGAGE   \n",
       "1  debt_consolidation               28.36%    TX       MORTGAGE   \n",
       "2  debt_consolidation               23.81%    CA       MORTGAGE   \n",
       "3  debt_consolidation               14.30%    KS       MORTGAGE   \n",
       "4         credit_card               18.78%    NJ           RENT   \n",
       "\n",
       "   Monthly.Income FICO.Range  Open.CREDIT.Lines  Revolving.CREDIT.Balance  \\\n",
       "0         6541.67    735-739               14.0                   14272.0   \n",
       "1         4583.33    715-719               12.0                   11140.0   \n",
       "2        11500.00    690-694               14.0                   21977.0   \n",
       "3         3833.33    695-699               10.0                    9346.0   \n",
       "4         3195.00    695-699               11.0                   14469.0   \n",
       "\n",
       "   Inquiries.in.the.Last.6.Months Employment.Length  \n",
       "0                             2.0          < 1 year  \n",
       "1                             1.0           2 years  \n",
       "2                             1.0           2 years  \n",
       "3                             0.0           5 years  \n",
       "4                             0.0           9 years  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LoansData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "776f312a-11b1-4669-9311-4111e1e76e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PearsonRResult(statistic=0.3358194064278584, pvalue=1.1396807200534781e-66)\n",
      "SpearmanResult: SignificanceResult(statistic=0.2825371874520007, pvalue=6.645782693641716e-47)\n"
     ]
    }
   ],
   "source": [
    "# Q.1 Interest rate is varied for different loan amounts (Less interest charged for high loan amounts)\n",
    "\n",
    "# Ho: Interest rate is same for all loan amounts\n",
    "# Ha: Interest rate is NOT same for all loan amounts\n",
    "# at CI=95%, p=0.05 \n",
    "\n",
    "# changing the data type of Interest.Rate to float\n",
    "df_LoansData['Interest.Rate'] = df_LoansData['Interest.Rate'].apply(lambda x:x[:len(x)-1]).astype(float)\n",
    "\n",
    "# Both variables are of continuous datatype, we will use correlation to find the relationship between 2 continuous variables\n",
    "print(stats.pearsonr(x=df_LoansData['Amount.Funded.By.Investors'], y=df_LoansData['Interest.Rate']))\n",
    "print('SpearmanResult:',stats.spearmanr(df_LoansData['Amount.Funded.By.Investors'], df_LoansData['Interest.Rate']))\n",
    "# At 95 % CI, calculated p-value is less than 0.05. So, we Reject the NULL hypothesis\n",
    "\n",
    "# Business Conclusion:\n",
    "# Interest Rate varies as per the loan amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac4b0a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=546.6073891678221, pvalue=1.9132344351553154e-109)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q.2 Loan length is directly effecting interest rate\n",
    "df_LoansData['Loan.Length'].unique() # has only 2 values. So categorical column\n",
    "\n",
    "# Ho: Loan length is NOT affecting interest rate\n",
    "# Ha: Loan length is affecting interest rate\n",
    "# at CI=95%, p=0.05 \n",
    "\n",
    "# Loan.Length is a categorical value & Interest.Rate is a continuous value. So, we perform ANOVA test\n",
    "\n",
    "# creating Series for each Loan.Length\n",
    "loan_length_36 = df_LoansData[df_LoansData['Loan.Length']=='36 months']['Interest.Rate'] # interest rates for 36 months\n",
    "loan_length_60 = df_LoansData[df_LoansData['Loan.Length']=='60 months']['Interest.Rate'] # interest rates for 60 months\n",
    "stats.f_oneway(loan_length_36, loan_length_60)\n",
    "# At 95 % CI, calculated p-value is less than 0.05. So, we Reject the NULL hypothesis\n",
    "\n",
    "# Business Conclusion:\n",
    "# Interest Rate depends on the duration of the loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36c747c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=7.487175499510107, pvalue=1.1346364693350775e-14)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q.3 Interest rate varies for different purpose of loans\n",
    "df_LoansData['Loan.Purpose'].unique() # Categorical column\n",
    "\n",
    "# Ho: Loan Purpose is NOT affecting interest rate\n",
    "# Ha: Loan Purpose is affecting interest rate\n",
    "# at CI=95%, p=0.05 \n",
    "\n",
    "# Loan.Purpose is a categorical value & Interest.Rate is a continuous value. So, we perform ANOVA test\n",
    "\n",
    "# creating Series for each Loan.Purpose\n",
    "loan_purpose_debt_consolidation = df_LoansData[df_LoansData['Loan.Purpose']=='debt_consolidation']['Interest.Rate'] # interest rates for debt_consolidation\n",
    "loan_purpose_credit_card = df_LoansData[df_LoansData['Loan.Purpose']=='credit_card']['Interest.Rate'] # interest rates for credit_card\n",
    "loan_purpose_other = df_LoansData[df_LoansData['Loan.Purpose']=='other']['Interest.Rate']  # interest rates for other\n",
    "loan_purpose_moving = df_LoansData[df_LoansData['Loan.Purpose']=='moving']['Interest.Rate'] # interest rates for moving\n",
    "loan_purpose_car = df_LoansData[df_LoansData['Loan.Purpose']=='car']['Interest.Rate'] # interest rates for car\n",
    "loan_purpose_vacation = df_LoansData[df_LoansData['Loan.Purpose']=='vacation']['Interest.Rate'] # interest rates for vacation\n",
    "loan_purpose_home_improvement = df_LoansData[df_LoansData['Loan.Purpose']=='home_improvement']['Interest.Rate'] # interest rates for home_improvement\n",
    "loan_purpose_house = df_LoansData[df_LoansData['Loan.Purpose']=='house']['Interest.Rate'] # interest rates for house\n",
    "loan_purpose_major_purchase = df_LoansData[df_LoansData['Loan.Purpose']=='major_purchase']['Interest.Rate'] # interest rates for major_purchase\n",
    "loan_purpose_educational = df_LoansData[df_LoansData['Loan.Purpose']=='educational']['Interest.Rate'] # interest rates for educational\n",
    "loan_purpose_medical = df_LoansData[df_LoansData['Loan.Purpose']=='medical']['Interest.Rate'] # interest rates for medical\n",
    "loan_purpose_wedding = df_LoansData[df_LoansData['Loan.Purpose']=='wedding']['Interest.Rate'] # interest rates for wedding\n",
    "loan_purpose_small_business = df_LoansData[df_LoansData['Loan.Purpose']=='small_business']['Interest.Rate'] # interest rates for small_business\n",
    "loan_purpose_renewable_energy = df_LoansData[df_LoansData['Loan.Purpose']=='renewable_energy']['Interest.Rate'] # interest rates for renewable_energy\n",
    "\n",
    "\n",
    "stats.f_oneway(loan_purpose_debt_consolidation, loan_purpose_credit_card, loan_purpose_other, loan_purpose_moving, loan_purpose_car, loan_purpose_vacation, loan_purpose_home_improvement, loan_purpose_house, loan_purpose_major_purchase, loan_purpose_educational, loan_purpose_medical, loan_purpose_wedding, loan_purpose_small_business, loan_purpose_renewable_energy )\n",
    "# At 95 % CI, calculated p-value is less than 0.05. So, we Reject the NULL hypothesis\n",
    "\n",
    "# Business Conclusion:\n",
    "# Interest Rate depends on the Purpose of the loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ca106bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=23.067768208374645, pvalue=1.001016973422469e-14)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q.4 There is relationship between FICO scores and Home Ownership. It means that, People with owning home will have high FICO scores.\n",
    "\n",
    "# FICO.Range is a categorical value. But here we will convert it into a continuous value for analysis. We are taking only the higher values in each FIICO range for analysis as it is the maximum value of FICO to be eligible to get that particular interest rate\n",
    "df_LoansData['FICO.Range_max_value'] = df_LoansData['FICO.Range'].apply(lambda x: x.split('-')[1])\n",
    "\n",
    "# Ho: There is NO relatioship between FICO scores and Home Ownership\n",
    "# Ha: There is a relationship between FICO scores and Home Ownership\n",
    "# at CI=95%, p=0.05\n",
    "\n",
    "# FICO.Range_max_value is a continuous value & Home.Ownership is a categorical value. So, we perform ANOVA test\n",
    "\n",
    "# creating data series for each Home Ownership type\n",
    "mydf_df_LoansData_Max_FICO_HomeOwnership_MORTGAGE = df_LoansData[df_LoansData['Home.Ownership'] == 'MORTGAGE']['FICO.Range_max_value']\n",
    "mydf_df_LoansData_Max_FICO_HomeOwnership_RENT = df_LoansData[df_LoansData['Home.Ownership'] == 'RENT']['FICO.Range_max_value']\n",
    "mydf_df_LoansData_Max_FICO_HomeOwnership_OWN = df_LoansData[df_LoansData['Home.Ownership'] == 'OWN']['FICO.Range_max_value']\n",
    "mydf_df_LoansData_Max_FICO_HomeOwnership_OTHER = df_LoansData[df_LoansData['Home.Ownership'] == 'OTHER']['FICO.Range_max_value']\n",
    "\n",
    "stats.f_oneway(mydf_df_LoansData_Max_FICO_HomeOwnership_MORTGAGE, mydf_df_LoansData_Max_FICO_HomeOwnership_RENT, mydf_df_LoansData_Max_FICO_HomeOwnership_OWN, mydf_df_LoansData_Max_FICO_HomeOwnership_OTHER)\n",
    "\n",
    "# At CI of 95%, calculated p-value is less than 0.05. SO, we reject the NULL hypothesis.\n",
    "\n",
    "# Business Conclusion:\n",
    "# There is a relationship between FICO scores and Home Ownership"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92170b7",
   "metadata": {},
   "source": [
    "# Business Problem 2: We would like to assess if there is any difference in the average price quotes provided by Mary and Barry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed451c57",
   "metadata": {},
   "source": [
    "BACKGROUND: When an order is placed by a customer of a small manufacturing company, a price quote must be developed for that order. Because each order is unique, quotes must be established on an order-by-order basis by a pricing expert. The price quote process is laborintensive, as prices depend on many factors such as the part number, customer, geographic location, market, and order volume. The sales department manager is concerned that the pricing process is too complex, and that there might be too much variability in the quoted prices. An improvement team is tasked with studying and improving the pricing process\n",
    "\n",
    "After interviewing experts to develop a better understanding of the current process, the team designed a study to determine if there is variability between pricing experts. That is, do different pricing experts provide different price quotes? Two randomly selected pricing experts, Mary and\n",
    "Barry, were asked to independently provide prices for twelve randomly selected orders. Each expert provided one price for each of the twelve orders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12a71263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order_Number</th>\n",
       "      <th>Barry_Price</th>\n",
       "      <th>Mary_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>138</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>142</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>146</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order_Number  Barry_Price  Mary_Price\n",
       "0             1          126         114\n",
       "1             2          110         118\n",
       "2             3          138         114\n",
       "3             4          142         111\n",
       "4             5          146         129"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Price_Quotes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a50110f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance of Barry_Price: 392.7222222222222\n",
      "variance of Mary_Price: 112.02083333333333\n",
      "the ratio of variance is: 3.505796292852272\n"
     ]
    }
   ],
   "source": [
    "print('variance of Barry_Price:',np.var(df_Price_Quotes['Barry_Price']))\n",
    "print('variance of Mary_Price:',np.var(df_Price_Quotes['Mary_Price']))\n",
    "print('the ratio of variance is:', np.var(df_Price_Quotes['Barry_Price']) / np.var(df_Price_Quotes['Mary_Price']))\n",
    "# Since the ratio of the larger data groups to the small data group is less than 4:1 then we can consider that the given data groups have equal variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fe18766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=1.4147436739281787, pvalue=0.17114226132118285, df=22.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ho: Mean of both Barry_Price & Mary_Price are same\n",
    "# Ha: Mean of both Barry_Price & Mary_Price are NOT same\n",
    "# at CI=95%, p=0.05\n",
    "\n",
    "# We are comparing the means of 2 variables & n<30. So, performing t-test\n",
    "stats.ttest_ind(df_Price_Quotes['Barry_Price'], df_Price_Quotes['Mary_Price'], equal_var=True)\n",
    "\n",
    "# At CI of 95%, calculated p-value is greater than 0.05. SO, we FAIL to reject the NULL hypothesis.\n",
    "\n",
    "# Business Conclusion:\n",
    "# There is NO difference in the average price quotes provided by Mary and Barry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29086dd3",
   "metadata": {},
   "source": [
    "# Business Problem 3: Determine what effect, if any, the reengineering effort had on the incidence behavioral problems and staff turnover. i.e To determine if the reengineering effort changed the critical incidence rate. Is there evidence that the critical incidence rate improved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae686c7",
   "metadata": {},
   "source": [
    "BACKGROUND: The New Life Residential Treatment Facility is a NGO that treats teenagers who have shown signs of mental illness. It provides housing and supervision of teenagers who are making the transition from psychiatric hospitals back into the community. Because many of the teenagers were severely abused as children and have been involved with the juvenile justice system, behavioral problems are common at New Life. Employee pay is low and staff turnover (attrition) is high.\n",
    "\n",
    "\n",
    "A reengineering program was instituted at New Life with the goals of lowering behavioral problems of the kids and decreasing employee turnover rates. As a part of this effort, the following changes were made:\n",
    "\n",
    "    a.Employee shifts were shortened from 10 hours to 8 hours each day.\n",
    "    \n",
    "    b.Employees were motivated to become more involved in patient treatments. This included encouraging staff to run various therapeutic treatment sessions and allowing staff to have more say in program changes.\n",
    "\n",
    "    c.The activities budget was increased.\n",
    "\n",
    "    d.A facility-wide performance evaluation system was put into place that rewarded staff participation and innovation.\n",
    "\n",
    "    e.Management and staff instituted a program designed to raise expectations about appropriate behavior from the kids. This included strict compliance with reporting of behavioral violations, insistence on participation in therapeutic sessions, and a lowered tolerance for even moderate behavioral infractions.\n",
    "    \n",
    "To determine the effectiveness of the reengineering effort, a data set comprised of pre- and post-reengineering periods was compiled. The information contains two measures of behavioral problems. A critical incident occurs when a resident goes AWOL (leaves the premises without permission), destroys property (e.g., punching a hole in a wall or throwing furniture through windows), is caught in possession of street drugs, or engages in assault against other residents or staff members. A teenager is temporarily removed from the facility when s/he is sent to jail or back to a psychiatric hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d0688fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Reengineer</th>\n",
       "      <th>Employee_Turnover</th>\n",
       "      <th>VAR4</th>\n",
       "      <th>VAR5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Prior</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>24.390244</td>\n",
       "      <td>42.682927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Prior</td>\n",
       "      <td>6.0606</td>\n",
       "      <td>19.354839</td>\n",
       "      <td>25.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Prior</td>\n",
       "      <td>12.1212</td>\n",
       "      <td>35.087719</td>\n",
       "      <td>146.198830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Prior</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>18.404908</td>\n",
       "      <td>110.429448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Prior</td>\n",
       "      <td>12.9032</td>\n",
       "      <td>17.964072</td>\n",
       "      <td>23.952096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month Reengineer  Employee_Turnover       VAR4        VAR5\n",
       "0      1      Prior             0.0000  24.390244   42.682927\n",
       "1      2      Prior             6.0606  19.354839   25.806452\n",
       "2      3      Prior            12.1212  35.087719  146.198830\n",
       "3      4      Prior             3.3333  18.404908  110.429448\n",
       "4      5      Prior            12.9032  17.964072   23.952096"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Treatment_Facility.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5c4586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the column names with proper names\n",
    "df_Treatment_Facility.columns = ['Month', 'Reengineer', 'Employee_Turnover', 'TRFF', 'CI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9754de7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=2.650105376271948, pvalue=0.12091989189884142)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1: Determine what effect, if any, the reengineering effort had on the incidence behavioral problems\n",
    "\n",
    "# Ho: There is NO diffrence on Incidence Behavioral Problems between Prior & post\n",
    "# Ha: There is a difference on Incidence Behavioral Problems between Prior & post\n",
    "# CI=95%, p=0.05\n",
    "# Reengineer column is categrical & CI column is continuous. So,we are performing ANOVA test\n",
    "\n",
    "CI_pre_reengineer = df_Treatment_Facility[df_Treatment_Facility['Reengineer']=='Prior']['CI']\n",
    "CI_post_reengineer = df_Treatment_Facility[df_Treatment_Facility['Reengineer']=='Post']['CI']\n",
    "\n",
    "stats.f_oneway(CI_pre_reengineer, CI_post_reengineer)\n",
    "# At CI of 95%, calculated p-value is greater than 0.05. SO, we FAIL to reject the NULL hypothesis.\n",
    "\n",
    "# Business Conclusion:\n",
    "# Critical Incidents have NOT changed by Reengineering effort. In other words, we can say that There is NO effect of Reengineering efforts on Critical Incidents. CI rate has NOT changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcce4781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=3.133985828895568, pvalue=0.09361109345535291)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2: Determine what effect, if any, the reengineering effort had on the Staff Turnover problems\n",
    "\n",
    "# Ho: There is NO diffrence on Staff Turnover problems between Prior & post\n",
    "# Ha: There is a difference on Staff Turnover problems between Prior & post\n",
    "# CI=95%, p=0.05\n",
    "# Reengineer column is categrical & Employee_Turnover column is continuous. So,we are performing ANOVA test\n",
    "\n",
    "Employee_Turnover_pre_reengineer = df_Treatment_Facility[df_Treatment_Facility['Reengineer']=='Prior']['Employee_Turnover']\n",
    "Employee_Turnover_post_reengineer = df_Treatment_Facility[df_Treatment_Facility['Reengineer']=='Post']['Employee_Turnover']\n",
    "\n",
    "stats.f_oneway(Employee_Turnover_pre_reengineer, Employee_Turnover_post_reengineer)\n",
    "# At CI of 95%, calculated p-value is greater than 0.05. SO, we FAIL to reject the NULL hypothesis.\n",
    "\n",
    "# Business Conclusion:\n",
    "# Employee Turnover have NOT changed by Reengineering effort. In other words, we can say that There is NO effect of Reengineering efforts on Employee Turnover. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeb1a1c",
   "metadata": {},
   "source": [
    "# Business Problem 4: We will focus on the prioritization system. If the system is working, then high priority jobs, on average, should be completed more quickly than medium priority jobs, and medium priority jobs should be completed more quickly than low priority jobs. Use the data provided to determine whether this is, in fact, occurring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f314a171",
   "metadata": {},
   "source": [
    "BACKGROUND: Software development projects typically follow six basic phases: Requirements, design, implementation (and integration), testing(validation), deployment (installation) and maintenance. First, general requirements are gathered, and the scope of the functionality is defined. Then, alternative scenarios for the required functionality are developed and evaluated. Implementation, usually 50% or more of the development time, is the phase in which the design is translated into programs and integrated with other parts of the software  this is when software engineers actually develop the code. During the final phases, programs are tested, software is put into use, and faults or performance issues are addressed.\n",
    "\n",
    "ApDudes, a developer of applications for tablet computers, was having difficulty meeting project deadlines; only 10% of their projects had been completed within budget and on time last year and that was starting to hurt business. The groups project manager was tasked with studying problems within the implementation phase. He found that software engineers were having difficulty prioritizing their work, and that they often became overwhelmed by the magnitude of the projects.\n",
    "    \n",
    "As a result, two changes were made. Each project was broken down into smaller, distinct tasks, or jobs, and each job was assigned a priority. The project manager believes that this classification and prioritization system would speed the completion of high priority jobs, and thus lower overall project completion time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c6b3cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Days</th>\n",
       "      <th>Priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.3</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.9</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.6</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Days Priority\n",
       "0   3.3     High\n",
       "1   7.9   Medium\n",
       "2   0.3     High\n",
       "3   0.7   Medium\n",
       "4   8.6   Medium"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Priority_Assessment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adc8ec16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['High', 'Medium', 'Low'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Priority_Assessment['Priority'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cba1e0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=1.812311010076072, pvalue=0.16411459461716182)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ho: There is NO difference by implementing prioritization system\n",
    "# Ha: There is a difference by implementing prioritization system\n",
    "# CI=95%, p=0.05\n",
    "# Priority column is categrical & Days column is continuous. So,we are performing ANOVA test\n",
    "\n",
    "prioritization_high = df_Priority_Assessment[df_Priority_Assessment['Priority']=='High']['Days']\n",
    "prioritization_medium = df_Priority_Assessment[df_Priority_Assessment['Priority']=='Medium']['Days']\n",
    "prioritization_low = df_Priority_Assessment[df_Priority_Assessment['Priority']=='Low']['Days']\n",
    "\n",
    "stats.f_oneway(prioritization_high, prioritization_medium, prioritization_low)\n",
    "# At CI of 95%, calculated p-value is greater than 0.05. SO, we FAIL to reject the NULL hypothesis.\n",
    "\n",
    "# Business Conclusion:\n",
    "# There is NO effect on project completion time by implementing prioritization system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72efd78b",
   "metadata": {},
   "source": [
    "# Business Problem 5:  Use the survey results to address the following questions\n",
    "    a. What is the overall level of customer satisfaction?\n",
    "    b. What factors are linked to satisfaction?\n",
    "    c. What is the demographic profile of Film on the Rocks patrons?\n",
    "    d. In what media outlet(s) should the film series be advertised?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a887adc",
   "metadata": {},
   "source": [
    "BackGround: Film on the Rocks is a summer movie series held at the world-renowned Red Rocks Amphitheatre, which is situated on a hillside of the Rocky Mountains in Morrison, Colorado fifteen miles west of Denver. The film series features classic films, and pre-show entertainment including bands and comedians. Among the features that have made Red Rocks an internationally-famous concert stage are sweeping views of Denver, outstanding acoustics, and cool, dry Colorado summers.\n",
    "\n",
    "The series is jointly promoted by the Denver Film Society (DFS) and the City and County of Denvers Division of Theatres and Arenas (DT&A). It is marketed through various outlets including newspaper, radio, and the Red Rocks and Denver Film Society websites. Film on the Rocks patrons also benefit from corporate sponsorship. In return for on-site posters and banners at Red Rocks, and recognition in pre- show marketing materials, corporations donate funds that keep ticket prices low.\n",
    "\n",
    "Although the Red Rocks Amphitheatre provides a cinematic experience unlike any other venue, there are tradeoffs. Red Rocks is a farther commute for most people than the local movie theater or movie rental store. Given the uphill walk to the amphitheatre from the parking lot, getting there can be challenging. And, as an outdoor venue, the viewing experience is dependent on the weather.\n",
    "    \n",
    "Patron satisfaction with Red Rocks as the venue for the film series is critical to its success. But, the series promoters would also like to increase attendance at the film series, and are unsure how to do this. Promoters recognize that they need a better understanding of the customer\n",
    "base, and of the current level of satisfaction. Knowing the demographics of those who attend the film series will help attract and expand corporate sponsorship. In addition, knowing which media outlets are most effective will provide information about how best to target future marketing campaigns.\n",
    "\n",
    "To this end, the promoters conducted surveys during a recent Film on the Rocks season. Questionnaires were handed out at the entrance. Volunteers walked through the crowd to remind people about the free soft drink given to those who returned the survey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86995080",
   "metadata": {},
   "source": [
    "The data set contains 330 surveys collected during three Film on the Rocks movies: Ferris Buellers Day Off, Old School, and Willy Wonka and the Chocolate Factory.\n",
    "\n",
    "The variables are:\n",
    "\n",
    "    a. Gender: The patrons gender: 1 = male; 2 = female\n",
    "    b. Marital Status: The patrons marital status: 1 = married; 2 = single\n",
    "    c. Age: The patrons age in years: 1= 1-12; 2 = 13-30; 3 = 31-60; 4 = 60+\n",
    "    d. Income: The patrons annual household income: 1 = Less than $50,000; 2 = $50,000-$100,000; 3 = $100,000+\n",
    "    e. Hear About: The patrons response to this question: How did you hear about Film on the Rocks? Respondents could check any of the following that applied: 1 = television; 2 = newspaper; 3 = radio; 4 = website; 5 = word of mouth\n",
    "\n",
    "\n",
    "    The survey also contained four Likert-scaled questions about satisfaction; each of the followingquestions is coded:\n",
    "\n",
    "    1 = Excellent; 2 = Good; 3 = Average/Fair; 4 = Poor; 5 = Very Poor.\n",
    "    a. Signage How was the signage directing you to Red Rocks?\n",
    "    b. Parking How was the venues parking?\n",
    "    c. Clean How was the cleanliness of the venue?\n",
    "    d. Overall How was your overall customer service experience?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53dc47e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_rowstate_</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Sinage</th>\n",
       "      <th>Parking</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Hear_About</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ferris Buellers Day Off</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ferris Buellers Day Off</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Ferris Buellers Day Off</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Ferris Buellers Day Off</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Ferris Buellers Day Off</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _rowstate_                    Movie  Gender Marital_Status  Sinage  \\\n",
       "0           0  Ferris Buellers Day Off  Female        Married     2.0   \n",
       "1           0  Ferris Buellers Day Off  Female         Single     1.0   \n",
       "2           0  Ferris Buellers Day Off    Male        Married     2.0   \n",
       "3           0  Ferris Buellers Day Off  Female        Married     1.0   \n",
       "4           0  Ferris Buellers Day Off  Female        Married     1.0   \n",
       "\n",
       "   Parking  Clean  Overall  Age  Income Hear_About  \n",
       "0      2.0    2.0      2.0  3.0     1.0          5  \n",
       "1      1.0    1.0      1.0  2.0     1.0          5  \n",
       "2      4.0    3.0      2.0  4.0     1.0          5  \n",
       "3      3.0    2.0      2.0  4.0     1.0          5  \n",
       "4      1.0    1.0      1.0  3.0     3.0          1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Films.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "271a0905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 330 entries, 0 to 329\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   _rowstate_      330 non-null    int64  \n",
      " 1   Movie           330 non-null    object \n",
      " 2   Gender          330 non-null    object \n",
      " 3   Marital_Status  328 non-null    object \n",
      " 4   Sinage          328 non-null    float64\n",
      " 5   Parking         328 non-null    float64\n",
      " 6   Clean           327 non-null    float64\n",
      " 7   Overall         328 non-null    float64\n",
      " 8   Age             328 non-null    float64\n",
      " 9   Income          314 non-null    float64\n",
      " 10  Hear_About      323 non-null    object \n",
      "dtypes: float64(6), int64(1), object(4)\n",
      "memory usage: 28.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_Films.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbcc374a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_rowstate_         0\n",
       "Movie              0\n",
       "Gender             0\n",
       "Marital_Status     2\n",
       "Sinage             2\n",
       "Parking            2\n",
       "Clean              3\n",
       "Overall            2\n",
       "Age                2\n",
       "Income            16\n",
       "Hear_About         7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Films.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c37b52ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_rowstate_        0.000000\n",
       "Movie             0.000000\n",
       "Gender            0.000000\n",
       "Marital_Status    0.606061\n",
       "Sinage            0.606061\n",
       "Parking           0.606061\n",
       "Clean             0.909091\n",
       "Overall           0.606061\n",
       "Age               0.606061\n",
       "Income            4.848485\n",
       "Hear_About        2.121212\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of NULL values in each column\n",
    "(df_Films.isnull().sum() / df_Films.shape[0] ) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "035f8778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the NULL value rows\n",
    "df_Films.dropna(subset=['Marital_Status', 'Sinage', 'Parking', 'Clean', 'Overall', 'Age', 'Income', 'Hear_About'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ded5f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 301 entries, 0 to 329\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   _rowstate_      301 non-null    int64  \n",
      " 1   Movie           301 non-null    object \n",
      " 2   Gender          301 non-null    object \n",
      " 3   Marital_Status  301 non-null    object \n",
      " 4   Sinage          301 non-null    float64\n",
      " 5   Parking         301 non-null    float64\n",
      " 6   Clean           301 non-null    float64\n",
      " 7   Overall         301 non-null    float64\n",
      " 8   Age             301 non-null    float64\n",
      " 9   Income          301 non-null    float64\n",
      " 10  Hear_About      301 non-null    object \n",
      "dtypes: float64(6), int64(1), object(4)\n",
      "memory usage: 28.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_Films.info()\n",
    "# we have removed approximately 10% of the data while removing the NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6058a2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So: 1.55 < level of satisfaction < 1.7\n"
     ]
    }
   ],
   "source": [
    "# a. What is the overall level of customer satisfaction?\n",
    "\n",
    "# Here we will find the point estimate of customer satisfaction\n",
    "# at CI=95%, p=0.05, alpha = 0.05\n",
    "# this is a 2 tail test, so z(alpha/2) = z(0.025) = 1.96\n",
    "point_estimate_upper_limit = np.round(df_Films['Overall'].mean() + (1.96 * (np.std(df_Films['Overall'])) / (np.sqrt(len(df_Films['Overall'])))),2)\n",
    "point_estimate_lower_limit = np.round(df_Films['Overall'].mean() - (1.96 * (np.std(df_Films['Overall'])) / (np.sqrt(len(df_Films['Overall'])))),2)\n",
    "\n",
    "print(f\"So: {point_estimate_lower_limit} < level of satisfaction < {point_estimate_upper_limit}\")\n",
    "#print(f\"the overall level of customer satisfaction is {df_Films['Overall'].mode()[0]}\")  *****do NOT use this this*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86969e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the values in columns to proper values as given in the problem statement\n",
    "\n",
    "df_Films['Gender'] = df_Films['Gender'].replace({'1':'Male', '2':'Female'})\n",
    "df_Films['Marital_Status'] = df_Films['Marital_Status'].replace({'1':'Married', '2':'Single', 'Slngle':'Single'})\n",
    "df_Films['Sinage'] = df_Films['Sinage'].replace({1.:'Excellent', 2.:'Good', 3.:'Average/Fair', 4.:'Poor', 5.:'Very Poor'})\n",
    "df_Films['Parking'] = df_Films['Parking'].replace({1.:'Excellent', 2.:'Good', 3.:'Average/Fair', 4.:'Poor', 5.:'Very Poor'})\n",
    "df_Films['Clean'] = df_Films['Clean'].replace({1.:'Excellent', 2.:'Good', 3.:'Average/Fair', 4.:'Poor', 5.:'Very Poor'})\n",
    "df_Films['Overall'] = df_Films['Overall'].replace({1.:'Excellent', 2.:'Good', 3.:'Average/Fair', 4.:'Poor', 5.:'Very Poor'})\n",
    "df_Films['Age'] = df_Films['Age'].replace({1.:'1-12', 2.:'13-30', 3.:'31-60', 4.:'60+'})\n",
    "df_Films['Income'] = df_Films['Income'].replace({1.:'< $50,000', 2.:'$50000 - $100,000', 3.:'> $100,000'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5bb4cbb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chi2ContingencyResult(statistic=13.76579813675212, pvalue=0.08807776417542347, dof=8, expected_freq=array([[ 5.10299003,  1.2358804 ,  5.66112957],\n",
       "       [58.25913621, 14.10963455, 64.63122924],\n",
       "       [62.93687708, 15.24252492, 69.82059801],\n",
       "       [ 0.42524917,  0.10299003,  0.4717608 ],\n",
       "       [ 1.27574751,  0.3089701 ,  1.41528239]]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b. What factors are linked to satisfaction?\n",
    "\n",
    "# Relationship between Overall_Satisfaction & Movie\n",
    "\n",
    "# Ho: There is NO relatioship between Overall_Satisfaction & Movie\n",
    "# Ha: There is a relationship between Overall_Satisfaction & Movie\n",
    "# at CI=95%, p=0.05\n",
    "# Overall is a categorical value & Movie is a categorical value. So, we perform Chi-Square test\n",
    "obs_freq_OverallandMovie = pd.crosstab(index=df_Films['Overall'], columns=df_Films['Movie'])\n",
    "# performing the chi-square test \n",
    "stats.chi2_contingency(obs_freq_OverallandMovie)\n",
    "# At CI of 95%, calculated p-value is more than 0.05. So, we FAIL to reject the NULL hypothesis.\n",
    "\n",
    "# Business Conclusion:\n",
    "# There is NO relatioship between Overall_Satisfaction & Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2825de23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chi2ContingencyResult(statistic=3.520985228074472, pvalue=0.4746946769990794, dof=4, expected_freq=array([[ 7.77408638,  4.22591362],\n",
       "       [88.75415282, 48.24584718],\n",
       "       [95.88039867, 52.11960133],\n",
       "       [ 0.64784053,  0.35215947],\n",
       "       [ 1.94352159,  1.05647841]]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relationship between Overall_Satisfaction & Gender\n",
    "\n",
    "# Ho: There is NO relatioship between Overall_Satisfaction & Gender\n",
    "# Ha: There is a relationship between Overall_Satisfaction & Gender\n",
    "# at CI=95%, p=0.05\n",
    "# Overall is a categorical value & Gender is a categorical value. So, we perform Chi-Square test\n",
    "obs_freq_OverallandGender = pd.crosstab(index=df_Films['Overall'], columns=df_Films['Gender'])\n",
    "# performing the chi-square test \n",
    "stats.chi2_contingency(obs_freq_OverallandGender)\n",
    "# At CI of 95%, calculated p-value is more than 0.05. So, we FAIL to reject the NULL hypothesis.\n",
    "\n",
    "# Business Conclusion:\n",
    "# There is NO relatioship between Overall_Satisfaction & Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4fbbe2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chi2ContingencyResult(statistic=4.716918153414503, pvalue=0.317595469011392, dof=4, expected_freq=array([[  3.62790698,   8.37209302],\n",
       "       [ 41.41860465,  95.58139535],\n",
       "       [ 44.74418605, 103.25581395],\n",
       "       [  0.30232558,   0.69767442],\n",
       "       [  0.90697674,   2.09302326]]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relationship between Overall_Satisfaction & Marital_Status\n",
    "\n",
    "# Ho: There is NO relatioship between Overall_Satisfaction & Marital_Status\n",
    "# Ha: There is a relationship between Overall_Satisfaction & Marital_Status\n",
    "# at CI=95%, p=0.05\n",
    "# Overall is a categorical value & Gender is a categorical value. So, we perform Chi-Square test\n",
    "obs_freq_OverallandMarital_Status = pd.crosstab(index=df_Films['Overall'], columns=df_Films['Marital_Status'])\n",
    "# performing the chi-square test \n",
    "stats.chi2_contingency(obs_freq_OverallandMarital_Status)\n",
    "# At CI of 95%, calculated p-value is more than 0.05. So, we FAIL to reject the NULL hypothesis.\n",
    "\n",
    "# Business Conclusion:\n",
    "# There is NO relatioship between Overall_Satisfaction & Marital_Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "85af7284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chi2ContingencyResult(statistic=121.32462033201087, pvalue=3.0544447763605627e-18, dof=16, expected_freq=array([[1.79401993e+00, 4.18604651e+00, 5.58139535e+00, 2.39202658e-01,\n",
       "        1.99335548e-01],\n",
       "       [2.04817276e+01, 4.77906977e+01, 6.37209302e+01, 2.73089701e+00,\n",
       "        2.27574751e+00],\n",
       "       [2.21262458e+01, 5.16279070e+01, 6.88372093e+01, 2.95016611e+00,\n",
       "        2.45847176e+00],\n",
       "       [1.49501661e-01, 3.48837209e-01, 4.65116279e-01, 1.99335548e-02,\n",
       "        1.66112957e-02],\n",
       "       [4.48504983e-01, 1.04651163e+00, 1.39534884e+00, 5.98006645e-02,\n",
       "        4.98338870e-02]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relationship between Overall_Satisfaction & Sinage\n",
    "\n",
    "# Ho: There is NO relatioship between Overall_Satisfaction & Sinage\n",
    "# Ha: There is a relationship between Overall_Satisfaction & Sinage\n",
    "# at CI=95%, p=0.05\n",
    "# Overall is a categorical value & Gender is a categorical value. So, we perform Chi-Square test\n",
    "obs_freq_OverallandSinage = pd.crosstab(index=df_Films['Overall'], columns=df_Films['Sinage'])\n",
    "# performing the chi-square test \n",
    "stats.chi2_contingency(obs_freq_OverallandSinage)\n",
    "# At CI of 95%, calculated p-value is less than 0.05. So, we reject the NULL hypothesis.\n",
    "\n",
    "# Business Conclusion:\n",
    "# There is a relatioship between Overall_Satisfaction & Sinage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0be26aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chi2ContingencyResult(statistic=218.79348282085004, pvalue=1.2264032549812005e-37, dof=16, expected_freq=array([[1.15614618e+00, 4.86378738e+00, 5.54152824e+00, 2.79069767e-01,\n",
       "        1.59468439e-01],\n",
       "       [1.31993355e+01, 5.55282392e+01, 6.32657807e+01, 3.18604651e+00,\n",
       "        1.82059801e+00],\n",
       "       [1.42591362e+01, 5.99867110e+01, 6.83455150e+01, 3.44186047e+00,\n",
       "        1.96677741e+00],\n",
       "       [9.63455150e-02, 4.05315615e-01, 4.61794020e-01, 2.32558140e-02,\n",
       "        1.32890365e-02],\n",
       "       [2.89036545e-01, 1.21594684e+00, 1.38538206e+00, 6.97674419e-02,\n",
       "        3.98671096e-02]]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relationship between Overall_Satisfaction & Parking\n",
    "\n",
    "# Ho: There is NO relatioship between Overall_Satisfaction & Parking\n",
    "# Ha: There is a relationship between Overall_Satisfaction & Parking\n",
    "# at CI=95%, p=0.05\n",
    "# Overall is a categorical value & Gender is a categorical value. So, we perform Chi-Square test\n",
    "obs_freq_OverallandParking = pd.crosstab(index=df_Films['Overall'], columns=df_Films['Parking'])\n",
    "# performing the chi-square test \n",
    "stats.chi2_contingency(obs_freq_OverallandParking)\n",
    "# At CI of 95%, calculated p-value is less than 0.05. So, we reject the NULL hypothesis.\n",
    "\n",
    "# Business Conclusion:\n",
    "# There is a relatioship between Overall_Satisfaction & Parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5236b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chi2ContingencyResult(statistic=129.03423923370684, pvalue=9.882317099745548e-20, dof=16, expected_freq=array([[8.77076412e-01, 5.34219269e+00, 5.50166113e+00, 1.99335548e-01,\n",
       "        7.97342193e-02],\n",
       "       [1.00132890e+01, 6.09900332e+01, 6.28106312e+01, 2.27574751e+00,\n",
       "        9.10299003e-01],\n",
       "       [1.08172757e+01, 6.58870432e+01, 6.78538206e+01, 2.45847176e+00,\n",
       "        9.83388704e-01],\n",
       "       [7.30897010e-02, 4.45182724e-01, 4.58471761e-01, 1.66112957e-02,\n",
       "        6.64451827e-03],\n",
       "       [2.19269103e-01, 1.33554817e+00, 1.37541528e+00, 4.98338870e-02,\n",
       "        1.99335548e-02]]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relationship between Overall_Satisfaction & Clean\n",
    "\n",
    "# Ho: There is NO relatioship between Overall_Satisfaction & Clean\n",
    "# Ha: There is a relationship between Overall_Satisfaction & Clean\n",
    "# at CI=95%, p=0.05\n",
    "# Overall is a categorical value & Gender is a categorical value. So, we perform Chi-Square test\n",
    "obs_freq_OverallandClean = pd.crosstab(index=df_Films['Overall'], columns=df_Films['Clean'])\n",
    "# performing the chi-square test \n",
    "stats.chi2_contingency(obs_freq_OverallandClean)\n",
    "# At CI of 95%, calculated p-value is less than 0.05. So, we reject the NULL hypothesis.\n",
    "\n",
    "# Business Conclusion:\n",
    "# There is a relatioship between Overall_Satisfaction & Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6de00b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chi2ContingencyResult(statistic=11.024837235069565, pvalue=0.5267913370930692, dof=12, expected_freq=array([[8.77076412e-01, 6.53820598e+00, 4.30564784e+00, 2.79069767e-01],\n",
       "       [1.00132890e+01, 7.46445183e+01, 4.91561462e+01, 3.18604651e+00],\n",
       "       [1.08172757e+01, 8.06378738e+01, 5.31029900e+01, 3.44186047e+00],\n",
       "       [7.30897010e-02, 5.44850498e-01, 3.58803987e-01, 2.32558140e-02],\n",
       "       [2.19269103e-01, 1.63455150e+00, 1.07641196e+00, 6.97674419e-02]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relationship between Overall_Satisfaction & Age\n",
    "\n",
    "# Ho: There is NO relatioship between Overall_Satisfaction & Age\n",
    "# Ha: There is a relationship between Overall_Satisfaction & Age\n",
    "# at CI=95%, p=0.05\n",
    "# Overall is a categorical value & Gender is a categorical value. So, we perform Chi-Square test\n",
    "obs_freq_OverallandAge = pd.crosstab(index=df_Films['Overall'], columns=df_Films['Age'])\n",
    "# performing the chi-square test \n",
    "stats.chi2_contingency(obs_freq_OverallandAge)\n",
    "# At CI of 95%, calculated p-value is more than 0.05. So, we FAIL to reject the NULL hypothesis.\n",
    "\n",
    "# Business Conclusion:\n",
    "# There is NO relatioship between Overall_Satisfaction & Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c3f8744d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chi2ContingencyResult(statistic=4.947873542642401, pvalue=0.7631326888324931, dof=8, expected_freq=array([[ 3.18936877,  5.3820598 ,  3.42857143],\n",
       "       [36.41196013, 61.44518272, 39.14285714],\n",
       "       [39.33554817, 66.37873754, 42.28571429],\n",
       "       [ 0.26578073,  0.44850498,  0.28571429],\n",
       "       [ 0.79734219,  1.34551495,  0.85714286]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relationship between Overall_Satisfaction & Income\n",
    "\n",
    "# Ho: There is NO relatioship between Overall_Satisfaction & Income\n",
    "# Ha: There is a relationship between Overall_Satisfaction & Income\n",
    "# at CI=95%, p=0.05\n",
    "# Overall is a categorical value & Gender is a categorical value. So, we perform Chi-Square test\n",
    "obs_freq_OverallandIncome = pd.crosstab(index=df_Films['Overall'], columns=df_Films['Income'])\n",
    "# performing the chi-square test \n",
    "stats.chi2_contingency(obs_freq_OverallandIncome)\n",
    "# At CI of 95%, calculated p-value is more than 0.05. So, we FAIL to reject the NULL hypothesis.\n",
    "\n",
    "# Business Conclusion:\n",
    "# There is NO relatioship between Overall_Satisfaction & Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "442323fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chi2ContingencyResult(statistic=21.659744148982803, pvalue=0.9920532791201511, dof=40, expected_freq=array([[7.57475083e-01, 3.98671096e-02, 4.38538206e-01, 7.97342193e-02,\n",
       "        5.18272425e-01, 3.98671096e-02, 3.98671096e-02, 1.55481728e+00,\n",
       "        3.98671096e-02, 8.45182724e+00, 3.98671096e-02],\n",
       "       [8.64784053e+00, 4.55149502e-01, 5.00664452e+00, 9.10299003e-01,\n",
       "        5.91694352e+00, 4.55149502e-01, 4.55149502e-01, 1.77508306e+01,\n",
       "        4.55149502e-01, 9.64916944e+01, 4.55149502e-01],\n",
       "       [9.34219269e+00, 4.91694352e-01, 5.40863787e+00, 9.83388704e-01,\n",
       "        6.39202658e+00, 4.91694352e-01, 4.91694352e-01, 1.91760797e+01,\n",
       "        4.91694352e-01, 1.04239203e+02, 4.91694352e-01],\n",
       "       [6.31229236e-02, 3.32225914e-03, 3.65448505e-02, 6.64451827e-03,\n",
       "        4.31893688e-02, 3.32225914e-03, 3.32225914e-03, 1.29568106e-01,\n",
       "        3.32225914e-03, 7.04318937e-01, 3.32225914e-03],\n",
       "       [1.89368771e-01, 9.96677741e-03, 1.09634551e-01, 1.99335548e-02,\n",
       "        1.29568106e-01, 9.96677741e-03, 9.96677741e-03, 3.88704319e-01,\n",
       "        9.96677741e-03, 2.11295681e+00, 9.96677741e-03]]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relationship between Overall_Satisfaction & Hear_About\n",
    "\n",
    "# Ho: There is NO relatioship between Overall_Satisfaction & Hear_About\n",
    "# Ha: There is a relationship between Overall_Satisfaction & Hear_About\n",
    "# at CI=95%, p=0.05\n",
    "# Overall is a categorical value & Gender is a categorical value. So, we perform Chi-Square test\n",
    "obs_freq_OverallandHear_About = pd.crosstab(index=df_Films['Overall'], columns=df_Films['Hear_About'])\n",
    "# performing the chi-square test \n",
    "stats.chi2_contingency(obs_freq_OverallandHear_About)\n",
    "# At CI of 95%, calculated p-value is more than 0.05. So, we FAIL to reject the NULL hypothesis.\n",
    "\n",
    "# Business Conclusion:\n",
    "# There is NO relatioship between Overall_Satisfaction & Hear_About"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6cb47ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe factors that are linked to Satisfaction are:\\n    1. Clean (cleanliness of the venue)\\n    2. Parking (venues parking)\\n    3. Sinage (signage directing you to Red Rocks)\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Upon conducting hypothesis testing on relationship between Overall_Satisfaction & all other variables. We have come to the conclusion that\n",
    "\"\"\"\n",
    "The factors that are linked to Satisfaction are:\n",
    "    1. Clean (cleanliness of the venue)\n",
    "    2. Parking (venues parking)\n",
    "    3. Sinage (signage directing you to Red Rocks)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b2c10b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Movie\n",
       "0  Female    195\n",
       "1    Male    106"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c. What is the demographic profile of Film on the Rocks patrons?\n",
    "\n",
    "# Demographic profile based on Gender\n",
    "\n",
    "df_Films.groupby('Gender').agg({'Movie':'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3fc2e91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Married</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Single</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Marital_Status  Movie\n",
       "0        Married     91\n",
       "1         Single    210"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demographic profile based on Marital Status\n",
    "df_Films.groupby('Marital_Status').agg({'Movie':'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f02d9df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-12</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13-30</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31-60</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60+</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Movie\n",
       "0   1-12     22\n",
       "1  13-30    164\n",
       "2  31-60    108\n",
       "3    60+      7"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demographic profile based on Marital Age\n",
    "df_Films.groupby('Age').agg({'Movie':'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e4014e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$50000 - $100,000</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt; $50,000</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&gt; $100,000</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Income  Movie\n",
       "0  $50000 - $100,000     80\n",
       "1          < $50,000    135\n",
       "2         > $100,000     86"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demographic profile based on Marital Status\n",
    "df_Films.groupby('Income').agg({'Movie':'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b44a504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
